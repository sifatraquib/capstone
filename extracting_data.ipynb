{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "communist-thong",
   "metadata": {},
   "source": [
    "### Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reduced-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import world_bank_data as wb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-massachusetts",
   "metadata": {},
   "source": [
    "Reading data from the web:\n",
    "\n",
    "We use the QoG OECD Time Series dataset to extract cross-national data for expenditure on environment protection, \n",
    "as percentage of total general government expenditure and world bank data of CO2 emission for corresponding countries\n",
    "and years. We further use economic growth, final government consumption expenditure (% of GDP) and \n",
    "Gross capital formation (% of GDP) from World Bank data bank.\n",
    "\n",
    "We first load the data from 1995.\n",
    "\n",
    "The dataset can be found at : https://www.gu.se/en/quality-government/qog-data/data-downloads/oecd-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "undefined-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://www.qogdata.pol.gu.se/data/qog_oecd_ts_jan21.csv')\n",
    "data = data[['cname', 'ccodealp', 'year', 'gfs_envr', 'wdi_co2', 'oecd_soxnox_t1a', 'oecd_soxnox_t1b', 'wdi_forest']]\n",
    "data = data[data['year'] >= 1995]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-planning",
   "metadata": {},
   "source": [
    "Now we generate a missing values table for report for environment expenditure to weed out countries and periods with most missing values to get a nearly balanced panel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "federal-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switzerland        1\n",
      "Austria            1\n",
      "Luxembourg         1\n",
      "Germany            1\n",
      "Italy              2\n",
      "Sweden             2\n",
      "Norway             2\n",
      "Czech Republic     2\n",
      "Portugal           2\n",
      "Slovenia           2\n",
      "Finland            2\n",
      "France (1963-)     2\n",
      "Spain              2\n",
      "Denmark            2\n",
      "Lithuania          2\n",
      "Ireland            2\n",
      "Latvia             2\n",
      "Greece             2\n",
      "Estonia            2\n",
      "Hungary            2\n",
      "Belgium            2\n",
      "United Kingdom     2\n",
      "Poland             2\n",
      "Slovakia           2\n",
      "United States      2\n",
      "Netherlands        2\n",
      "Australia          5\n",
      "Iceland            6\n",
      "Israel             6\n",
      "Japan             12\n",
      "Turkey            14\n",
      "New Zealand       15\n",
      "Korea, South      24\n",
      "Canada            26\n",
      "Chile             26\n",
      "Mexico            26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def gen_nan_report(data, x):\n",
    "    countries = data['cname'].value_counts().index\n",
    "    years = data['year'].value_counts().index\n",
    "    missing_values = {}\n",
    "\n",
    "    for i in range(len(countries)):\n",
    "        country = countries[i]\n",
    "        m1 = {}\n",
    "        for j in range(len(years)):\n",
    "            year = years[j]\n",
    "            subset = data[np.logical_and(data['cname'] == country, data['year'] == year)][x]\n",
    "            nans = subset.isnull().values.ravel().sum()\n",
    "            m1.update({year : nans})\n",
    "        missing_values.update({country : m1})\n",
    "    return missing_values\n",
    "\n",
    "countries = data['cname'].value_counts().index\n",
    "\n",
    "nan_env = pd.DataFrame(gen_nan_report(data=data, x='gfs_envr'))\n",
    "\n",
    "missing_value_per_country = {country : nan_env.loc[:, country].sum() for country in countries}\n",
    "\n",
    "print(pd.Series(missing_value_per_country).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-conspiracy",
   "metadata": {},
   "source": [
    "We weed out any country that has more than 2 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cname ccodealp  year  gfs_envr   wdi_co2  oecd_soxnox_t1a  \\\n",
      "124  Austria      AUT  1995  2.132733  7.538586           46.929   \n",
      "125  Austria      AUT  1996  2.256715  7.957359           44.087   \n",
      "126  Austria      AUT  1997  0.723879  7.881156           40.244   \n",
      "127  Austria      AUT  1998  0.800405  7.998933           35.638   \n",
      "128  Austria      AUT  1999  0.884917  7.759483           33.723   \n",
      "\n",
      "     oecd_soxnox_t1b  wdi_forest  \n",
      "124          199.917   46.100751  \n",
      "125          217.706   46.175829  \n",
      "126          204.490   46.250907  \n",
      "127          216.869   46.325988  \n",
      "128          208.297   46.401066  \n"
     ]
    }
   ],
   "source": [
    "bad_countries = [country for country, value in missing_value_per_country.items() if value > 2]\n",
    "data = data[~(data.cname.isin(bad_countries))]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-ethics",
   "metadata": {},
   "source": [
    "Now we weed out the 2 bad years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boxed-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006     0\n",
      "2017     0\n",
      "2016     0\n",
      "2015     0\n",
      "2014     0\n",
      "2013     0\n",
      "2012     0\n",
      "2011     0\n",
      "2010     0\n",
      "2009     0\n",
      "2008     0\n",
      "2007     0\n",
      "1995     0\n",
      "2005     0\n",
      "2004     0\n",
      "2003     0\n",
      "2002     0\n",
      "2001     0\n",
      "2000     0\n",
      "1999     0\n",
      "1998     0\n",
      "1997     0\n",
      "1996     0\n",
      "2018     0\n",
      "2019    22\n",
      "2020    26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_env = nan_env.drop(columns=bad_countries)\n",
    "years = data.year.value_counts().index\n",
    "missing_values_per_year = {year : nan_env.loc[year, :].sum() for year in years}\n",
    "print(pd.Series(missing_values_per_year).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-platinum",
   "metadata": {},
   "source": [
    "They are 2019 and 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "manufactured-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_years = [year for year, val in missing_values_per_year.items() if val > 0]\n",
    "data = data[~(data.year.isin(bad_years))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-progressive",
   "metadata": {},
   "source": [
    "Now let's look at the missing value report for co2 emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "satellite-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium           2\n",
      "Finland           2\n",
      "Germany           2\n",
      "Denmark           2\n",
      "Spain             2\n",
      "Luxembourg        2\n",
      "Slovakia          2\n",
      "Estonia           2\n",
      "Hungary           2\n",
      "Ireland           2\n",
      "Austria           2\n",
      "Lithuania         2\n",
      "Latvia            2\n",
      "Poland            2\n",
      "Portugal          2\n",
      "Czech Republic    2\n",
      "Norway            2\n",
      "Sweden            2\n",
      "United States     2\n",
      "Netherlands       2\n",
      "Greece            2\n",
      "United Kingdom    2\n",
      "Switzerland       2\n",
      "Slovenia          2\n",
      "France (1963-)    4\n",
      "Italy             4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_co2 = pd.DataFrame(gen_nan_report(data=data, x='wdi_co2'))\n",
    "countries = data['cname'].value_counts().index\n",
    "missing_value_per_country_co2 = {country : nan_co2.loc[:, country].sum() for country in countries}\n",
    "print(pd.Series(missing_value_per_country_co2).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-width",
   "metadata": {},
   "source": [
    "We weed out any country that has more than 2 missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "about-playing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cname ccodealp  year  gfs_envr   wdi_co2  oecd_soxnox_t1a  \\\n",
      "124  Austria      AUT  1995  2.132733  7.538586           46.929   \n",
      "125  Austria      AUT  1996  2.256715  7.957359           44.087   \n",
      "126  Austria      AUT  1997  0.723879  7.881156           40.244   \n",
      "127  Austria      AUT  1998  0.800405  7.998933           35.638   \n",
      "128  Austria      AUT  1999  0.884917  7.759483           33.723   \n",
      "\n",
      "     oecd_soxnox_t1b  wdi_forest  \n",
      "124          199.917   46.100751  \n",
      "125          217.706   46.175829  \n",
      "126          204.490   46.250907  \n",
      "127          216.869   46.325988  \n",
      "128          208.297   46.401066  \n"
     ]
    }
   ],
   "source": [
    "bad_countries_co2 = [country for country, value in missing_value_per_country_co2.items() if value > 2]\n",
    "data = data[~(data.cname.isin(bad_countries_co2))]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-bonus",
   "metadata": {},
   "source": [
    "Now let's weed out 2 more bad years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tender-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005     0\n",
      "2015     0\n",
      "2014     0\n",
      "2013     0\n",
      "2012     0\n",
      "2011     0\n",
      "2010     0\n",
      "2009     0\n",
      "2008     0\n",
      "2007     0\n",
      "2006     0\n",
      "1995     0\n",
      "2004     0\n",
      "2003     0\n",
      "2002     0\n",
      "2001     0\n",
      "2000     0\n",
      "1999     0\n",
      "1998     0\n",
      "1997     0\n",
      "1996     0\n",
      "2016     0\n",
      "2017    24\n",
      "2018    24\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_co2 = nan_co2.drop(columns=bad_countries_co2)\n",
    "years = data.year.value_counts().index\n",
    "missing_values_per_year_co2 = {year : nan_co2.loc[year, :].sum() for year in years}\n",
    "print(pd.Series(missing_values_per_year_co2).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-mason",
   "metadata": {},
   "source": [
    "They are 2017 and 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "focused-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_years = [year for year, val in missing_values_per_year_co2.items() if val > 0]\n",
    "data = data[~(data.year.isin(bad_years))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-break",
   "metadata": {},
   "source": [
    "Note that now it is a completely balanced dataset. Now we GDP growth (annual %), General government final consumption expenditure (% of GDP), and Gross capital formation (% of GDP) data from World Bank Data Bank. Then, we will look at how many countries we have and the year range. Access the following links for further data description.\n",
    "\n",
    "- GDP growth : https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG\n",
    "- General government final consumption expenditure (% of GDP) : https://data.worldbank.org/indicator/NE.CON.GOVT.ZS\n",
    "- Gross capital formation (% of GDP) : https://data.worldbank.org/indicator/NE.GDI.TOTL.ZS\n",
    "- Industry formation (% of GDP) :https://data.worldbank.org/indicator/NV.IND.TOTL.ZS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "widespread-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rates = {}\n",
    "gov_exp = {}\n",
    "gross_capital = {}\n",
    "industry_share = {}\n",
    "\n",
    "ccodes = data['ccodealp'].value_counts().index\n",
    "\n",
    "for j in range(len(ccodes)):\n",
    "    c = ccodes[j]\n",
    "    growth = wb.get_series('NY.GDP.MKTP.KD.ZG', country=c, id_or_value='id', simplify_index=True)\n",
    "    govexp = wb.get_series('NE.CON.GOVT.ZS', country=c, id_or_value='id', simplify_index=True)\n",
    "    grosscap = wb.get_series('NE.GDI.TOTL.ZS', country=c, id_or_value='id', simplify_index=True)\n",
    "    indshare = wb.get_series('NV.IND.TOTL.ZS', country=c, id_or_value='id', simplify_index=True)\n",
    "    growth_rates.update({c : growth})\n",
    "    gov_exp.update({c : govexp})\n",
    "    gross_capital.update({c : grosscap})\n",
    "    industry_share.update({c : indshare})\n",
    "\n",
    "growth_columns = ['ccodealp', 'year', 'growth_rate']\n",
    "growth_rates = pd.DataFrame(growth_rates).unstack().reset_index()\n",
    "growth_rates.columns = growth_columns\n",
    "\n",
    "gov_exp_columns = ['ccodealp', 'year', 'gov_exp']\n",
    "gov_exp = pd.DataFrame(gov_exp).unstack().reset_index()\n",
    "gov_exp.columns = gov_exp_columns\n",
    "\n",
    "gross_capital_columns = ['ccodealp', 'year', 'gross_capital']\n",
    "gross_capital = pd.DataFrame(gross_capital).unstack().reset_index()\n",
    "gross_capital.columns = gross_capital_columns\n",
    "\n",
    "industry_share_columns = ['ccodealp', 'year', 'industry_share']\n",
    "industry_share = pd.DataFrame(industry_share).unstack().reset_index()\n",
    "industry_share.columns = industry_share_columns\n",
    "\n",
    "wb0 = growth_rates.merge(gov_exp, left_on=['ccodealp', 'year'], right_on=['ccodealp', 'year'])\n",
    "wb1 = wb0.merge(gross_capital, left_on=['ccodealp', 'year'], right_on=['ccodealp', 'year'])\n",
    "wb_data = wb1.merge(industry_share, left_on=['ccodealp', 'year'], right_on=['ccodealp', 'year'])\n",
    "\n",
    "wb_data.year = wb_data.year.astype(int)\n",
    "wb_data = wb_data[np.logical_and(wb_data['year'] >= 1995, wb_data['year'] <= 2016)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-process",
   "metadata": {},
   "source": [
    "Finally, we merge World Bank data with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sustained-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(wb_data, left_on=['ccodealp', 'year'], right_on=['ccodealp', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-solid",
   "metadata": {},
   "source": [
    "We drop United States from the dataset as the datset shows that it contributed zero percent of government expenditure to environmental protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "billion-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['ccodealp'] != 'USA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-phoenix",
   "metadata": {},
   "source": [
    "The final data has the following countries, and it ranges from 1995-2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "floppy-friday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Switzerland', 'Belgium', 'United Kingdom', 'Greece', 'Netherlands', 'Sweden', 'Norway', 'Czech Republic', 'Portugal', 'Poland', 'Slovenia', 'Austria', 'Lithuania', 'Ireland', 'Hungary', 'Estonia', 'Slovakia', 'Luxembourg', 'Spain', 'Denmark', 'Germany', 'Finland', 'Latvia']\n"
     ]
    }
   ],
   "source": [
    "print([x for x in data.cname.value_counts().index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-offense",
   "metadata": {},
   "source": [
    "Save the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "discrete-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('/Users/brianyang/Desktop/nyu/Capstone/Capstone-Project/data/capstone_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
